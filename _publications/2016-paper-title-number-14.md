---
title: "Revisiting Useful Approaches to Data-Rich Macroeconomic Forecasting"
collection: publications
permalink: /publication/2016-paper-title-number-14
date: 2016-08-01
venue: 'Computational Statistics & Data Analysis'
link: 'https://dx.doi.org/10.1016/j.csda.2015.11.014'
citation: 'Groen, J.J.J. and G. Kapetanios (2016). &quot;Revisiting Useful Approaches to Data-Rich Macroeconomic Forecasting&quot; <i>Computational Statistics & Data Analysis</i>. 100, pp. 221-239.'

The properties of a number of data-rich methods that are widely used in macroeconomic forecasting are analyzed. In particular, this analysis focuses on principal components (PC) and Bayesian regressions, as well as a lesser known alternative, partial least squares (PLS) regression. In the latter method, linear, orthogonal combinations of a large number of predictor variables are constructed such that the covariance between a target variable and these common components is maximized. Existing studies have focused on modeling the target variable as a function of a finite set of unobserved common factors that underlies a large set of predictor variables, but here it is assumed that this target variable depends directly on the whole set of predictor variables. Given this set up it is shown theoretically that under a variety of different unobserved factor structures, PLS and Bayesian regressions provide asymptotically the best fit for the target variable of interest. This includes the case of an asymptotically weak factor structure for the predictor variables, for which it is known that PC regression becomes inconsistent. Monte Carlo experiments confirm that PLS regression is close to Bayesian regression when the data has a factor structure. When the factor structure in the data becomes weak, PLS and Bayesian regressions outperform principal components. Finally, PLS, principal components, and Bayesian regressions are applied on a large panel of monthly U.S. macroeconomic data to forecast key variables across different subperiods, and PLS and Bayesian regressions usually have the best out-of-sample performances.
---
